{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 150, 10)           200000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 300)              193200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 40)                12040     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 123       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 405,363\n",
      "Trainable params: 405,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('LSTM.h5',compile = True)\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total null text     0\n",
      "count    0\n",
      "dtype: int64\n",
      "total null text     0\n",
      "count    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_predict = pd.read_excel(\"alif new.xlsx\")\n",
    "data_predict = data_predict.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "print(f\"total null {data_predict.isnull().sum()}\")\n",
    "print(f\"total null {data_predict.isna().sum()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwisb\\AppData\\Local\\Temp/ipykernel_1160/3460411168.py:26: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_predict['text'] = data_predict['text'].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "data_predict['text'] = data_predict['text'].replace({'\"':'',\n",
    "                                 '\\d+':'',\n",
    "                                 ':':'',\n",
    "                                 ';':'',\n",
    "                                 '#':'',\n",
    "                                 '_':'',\n",
    "                                 ',': '',\n",
    "                                 \"'\": '',\n",
    "                                  }, regex=True)\n",
    "\n",
    "data_predict['text'] = data_predict['text'].str.replace(r'[https]+[?://]+[^\\s<>\"]+|www\\.[^\\s<>\"]+[?()]+[(??)]+[)*]+[(\\xa0]+[-&gt]', \"\",regex=True)\n",
    "\n",
    "data_predict['text'] = data_predict['text'].replace('\\n','', regex=True)\n",
    "\n",
    "data_predict['text'] = data_predict['text'].replace({'\\.':'','(/)':'','\\(':'','\\)':''},regex=True)\n",
    "data_predict['text'] = data_predict['text'].replace('[\\.:\"]','',regex =True)\n",
    "data_predict['text'] = data_predict['text'].replace('\\?', '', regex=True)\n",
    "data_predict['text'] = data_predict['text'].replace('\\!', '', regex=True)\n",
    "data_predict['text'] = data_predict['text'].replace('\\*', '', regex=True)\n",
    "data_predict['text'] = data_predict['text'].replace('\\%', '', regex=True)\n",
    "data_predict['text'] = data_predict['text'].replace('\\&', '', regex=True)\n",
    "data_predict['text'] = data_predict['text'].replace('\\~', '', regex=True)\n",
    "data_predict['text'] = data_predict['text'].replace('\\=', ' ', regex=True)\n",
    "data_predict['text'] = data_predict['text'].replace('\\-', '', regex=True)\n",
    "data_predict['text'] = data_predict['text'].replace('@', ' ', regex=True)\n",
    "data_predict['text'] = data_predict['text'].str.replace(r'[^\\w\\s]+', '')\n",
    "#data_predict['text'].astype(str)\n",
    "data_predict['text'] = data_predict['text'].replace('\\s+', ' ', regex=True)\n",
    "data_predict['text'] = data_predict['text'].str.strip()\n",
    "data_predict['text'] = data_predict['text'].str.lower()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['pos indonesia menaikkan tarif pengantaran barang kiriman impor terhitung sejak september hal itu dikarenakan terdapat perubahan permenkeu tentang ketentuan kepabeanan cukai dan pajak atas impor barang kiriman',\n 'kehadiran pospay dari pt pos indonesia semakin meluas di tengah masyarakat indonesia per awal november ini setidaknya terdapat lebih dari juta masyarakat telah mengunduh aplikasi pospay di gawai masingmasing jokowi',\n 'open jasa admin packing dom depok jabar deket ekspedisi jnt jne pos indonesia shopee express wahana shopee freeong sudah biasa packing krn collector jg bahan packing bisa dari kami sendiri jg bs harga bisa dibicarakan di dm yuk',\n 'bayar pajak motor mudah bgt isi kelengkapantransfer via mbanking terus tunggu dianter via pos indonesianama aplikasi signalpolri',\n 'momentum november bukan hanya sebatas peringatan pemuda harus mengambil peran untuk meneruskan apa yang sudah diperjuangkan oleh para pendahulu bangsa ini gerak nyata oleh pc gp ansor kabupaten probolinggo bersama pt pos indonesia']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_predict['text'].tolist()\n",
    "data[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "vocab_size = 20000\n",
    "embedding_dim = 10\n",
    "max_length = 150\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = \"<OOV>\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X = data\n",
    "tokenizer = Tokenizer(num_words=vocab_size,oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "padded = pad_sequences(sequences,maxlen=max_length,padding=padding_type,truncating=trunc_type)\n",
    "predic = model.predict(padded)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "y_label = {0:\"negative\",1:\"neutral\",2:\"positive\"}\n",
    "sentimen = []\n",
    "for x in predic:\n",
    "    sentimen.append(y_label[np.argmax(x)])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "data_clean = pd.DataFrame({'tweet':data_predict['text'],'sentimen':sentimen,'count':data_predict['count']})\n",
    "data_clean.to_excel(\"POS INDONESIA SENTIMEN.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}